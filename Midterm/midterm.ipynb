{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization\n",
    "## Logic Definition of Generalization:\n",
    "1. Show empirically that the information limit of 2 prediction bits per parameter also holds for nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_dimensions  avg_predicted_points  n_full/n_average\n",
      "0             1              0.500000          4.000000\n",
      "1             2              2.625000          1.523810\n",
      "2             3              4.166667          1.920000\n",
      "3             4              8.500000          1.882353\n",
      "4             5             15.450000          2.071197\n",
      "5             6             33.250000          1.924812\n",
      "6             7             63.750000          2.007843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "def n_full(d):\n",
    "    return 2**d\n",
    "\n",
    "def generate_dataset(n_samples, n_dimensions):\n",
    "    \"\"\"Generates a dataset of random points and random labels.\"\"\"\n",
    "    X = np.random.rand(n_samples, n_dimensions)\n",
    "    y = np.random.randint(2, size=n_samples)  # Binary labels\n",
    "    return X, y\n",
    "\n",
    "def train_test_split(X, y, test_size=0.5):\n",
    "    \"\"\"Splits the dataset into training and test sets.\"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(n_samples * test_size)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    training_idx, test_idx = indices[n_test:], indices[:n_test]\n",
    "    return X[training_idx], X[test_idx], y[training_idx], y[test_idx]\n",
    "\n",
    "def count_required_points(X, y):\n",
    "    \"\"\"Counts how many points are required to perfectly predict the training set using 1-NN.\"\"\"\n",
    "    # split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    correct_predictions = (predictions == y_test)\n",
    "    required_points_indices = np.where(correct_predictions == True)[0]\n",
    "    return len(required_points_indices)\n",
    "\n",
    "def experiment(n_dimensions, n_samples):\n",
    "    \"\"\"Conducts the experiment for a given dimensionality and number of functions.\"\"\"\n",
    "    required_points = []\n",
    "    \n",
    "    for _ in range(n_dimensions * 8):\n",
    "        X, y = generate_dataset(n_samples, n_dimensions)\n",
    "        n_required = count_required_points(X, y)\n",
    "        required_points.append(n_required)\n",
    "        \n",
    "    avg_required_points = np.mean(required_points) * 2 # Multiply by 2 because we only used half of the data\n",
    "    return n_dimensions, avg_required_points, n_samples / avg_required_points\n",
    "\n",
    "# Define the dimensions and number of functions for each dimensionality\n",
    "dimensions_functions = [(x, n_full(x)) for x in range(1, 8)]\n",
    "\n",
    "# Conduct the experiment for each dimensionality\n",
    "results = [experiment(d, n) for d, n in dimensions_functions]\n",
    "\n",
    "results = pd.DataFrame(results, columns=[\"n_dimensions\", \"avg_predicted_points\", \"n_full/n_average\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 0.5666666666666667)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "# Generate a synthetic binary dataset\n",
    "np.random.seed(0)\n",
    "n_samples = 100\n",
    "n_features = 4\n",
    "X = np.random.randint(2, size=(n_samples, n_features))  # Features\n",
    "y = np.random.randint(2, size=n_samples)  # Binary target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "def generate_if_then_clauses(X, y):\n",
    "    \"\"\"\n",
    "    Generates if-then clauses from the training data and attempts to minimize them.\n",
    "    \"\"\"\n",
    "    clauses = []\n",
    "    for index, row in enumerate(X):\n",
    "        clause = \"IF \"\n",
    "        for i, val in enumerate(row):\n",
    "            clause += f\"feature_{i} == {val} AND \"\n",
    "        clause = clause.rstrip(\" AND \") + f\" THEN outcome == {y[index]}\"\n",
    "        clauses.append(clause)\n",
    "    \n",
    "    # Basic minimization strategy: Deduplication\n",
    "    unique_clauses = list(set(clauses))\n",
    "    \n",
    "    return unique_clauses\n",
    "\n",
    "def evaluate_clauses(clauses, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the generated clauses on a test set for accuracy.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for test_row in X_test:\n",
    "        prediction = None\n",
    "        for clause in clauses:\n",
    "            condition, outcome = clause.split(\" THEN \")\n",
    "            condition = condition.replace(\"IF \", \"\").split(\" AND \")\n",
    "            if all(f\"feature_{i} == {int(test_row[i])}\" in condition for i in range(len(test_row))):\n",
    "                _, outcome_val = outcome.split(\" == \")\n",
    "                prediction = int(outcome_val)\n",
    "                break\n",
    "        if prediction is None:\n",
    "            prediction = 0  # Default to 0 if no clause matches\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Generate and evaluate clauses\n",
    "clauses = generate_if_then_clauses(X_train, y_train)\n",
    "accuracy = evaluate_clauses(clauses, X_test, y_test)\n",
    "\n",
    "len(clauses), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_clauses</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_clauses  accuracy\n",
       "0           2          8  0.466667\n",
       "1           4         29  0.466667\n",
       "2           6         49  0.533333\n",
       "3           8         61  0.633333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to generate and evaluate synthetic datasets of varying complexity\n",
    "def experiment_with_synthetic_datasets(n_instances, feature_counts):\n",
    "    results = []\n",
    "    for n_features in feature_counts:\n",
    "        # Generate a synthetic dataset\n",
    "        X = np.random.randint(2, size=(n_instances, n_features))\n",
    "        y = np.random.randint(2, size=n_instances)\n",
    "        \n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Generate and evaluate clauses\n",
    "        clauses = generate_if_then_clauses(X_train, y_train)\n",
    "        accuracy = evaluate_clauses(clauses, X_test, y_test)\n",
    "        \n",
    "        results.append({\"n_features\": n_features, \"n_clauses\": len(clauses), \"accuracy\": accuracy})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Experiment with synthetic datasets with varying number of features\n",
    "n_instances = 100\n",
    "feature_counts = [2, 4, 6, 8]\n",
    "synthetic_results = experiment_with_synthetic_datasets(n_instances, feature_counts)\n",
    "synthetic_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Select a subset of columns for simplicity and handle categorical variables\n",
    "features_to_use = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Survived']\n",
    "titanic_data = titanic_data[features_to_use].dropna()\n",
    "\n",
    "# Convert 'Sex' to a binary variable\n",
    "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Prepare the data\n",
    "X_titanic = titanic_data.drop('Survived', axis=1).values\n",
    "y_titanic = titanic_data['Survived'].values\n",
    "\n",
    "# Split the dataset\n",
    "X_train_titanic, X_test_titanic, y_train_titanic, y_test_titanic = train_test_split(X_titanic, y_titanic, test_size=0.3, random_state=42)\n",
    "\n",
    "# Generate and evaluate clauses on the Titanic dataset\n",
    "clauses_titanic = generate_if_then_clauses(X_train_titanic, y_train_titanic)\n",
    "accuracy_titanic = evaluate_clauses(clauses_titanic, X_test_titanic, y_test_titanic)\n",
    "\n",
    "len(clauses_titanic), accuracy_titanic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
